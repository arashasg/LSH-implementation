{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " lsh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Name: Arash Asgari\n",
        "### Student number: 400201037"
      ],
      "metadata": {
        "id": "kvx__iAC5Pkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "CSmLpAtf5MoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_distances"
      ],
      "metadata": {
        "id": "sgAqpo3Fs-Yw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iWD46jsj4gaP"
      },
      "outputs": [],
      "source": [
        "def create_fake_data(N, d):\n",
        "    # returns X array with shape (N, d)\n",
        "    vec = np.random.rand(N, d)\n",
        "    vec = np.floor(vec * 99)\n",
        "    return vec\n",
        "\n",
        "def cosine_distance(x, y):\n",
        "    # returns cosine distance between x and y\n",
        "    cos_sim = np.dot(x, y.T)/(np.linalg.norm(x)*np.linalg.norm(y))\n",
        "    return 1 - cos_sim\n",
        "\n",
        "def find_k_nearest_neighbours(X, q, k):\n",
        "    # returns indexes of the k-nearest-neighbours of vector q\n",
        "    distances = np.zeros(X.shape[0])\n",
        "    for ind, vec in enumerate(X):\n",
        "      distances[ind] = cosine_distance(vec, np.array(q))\n",
        "    return np.argsort(distances)[:k]\n",
        "\n",
        "def find_k_farest_neighbours(X, q, k):\n",
        "    # returns indexes of the k-farest-neighbours of vector q\n",
        "    distances = np.zeros(X.shape[0])\n",
        "    for ind, vec in enumerate(X):\n",
        "      distances[ind] = cosine_distance(vec, q)\n",
        "    return np.argsort(distances)[-k:]\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f_data = create_fake_data(1000, 2)\n",
        "data = np.array([[3, 4], [5, 10], [-3, -4], [6, 9]])\n",
        "find_k_nearest_neighbours(data, (3, 4), 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI1dXTvD1NKC",
        "outputId": "ae269892-7195-4def-e4b9-d7bfeaa2a817"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 3, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each object of hash table is a min hashing instance."
      ],
      "metadata": {
        "id": "mqDfMgCoR_Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HashTable:\n",
        "    def __init__(self, hash_size, inp_dimensions):\n",
        "        self.hash_size = hash_size\n",
        "        self.inp_dimensions = inp_dimensions\n",
        "        self.hash_table = dict()\n",
        "        self.projections = np.random.randn(self.hash_size, inp_dimensions)\n",
        "        \n",
        "    def generate_hash(self, inp_vector):\n",
        "        bools = (np.dot(inp_vector, self.projections.T) > 0).astype('int')\n",
        "        bools = np.squeeze(bools)\n",
        "        return ''.join(bools.astype('str'))\n",
        "\n",
        "    def __setitem__(self, inp_vec, label):\n",
        "        hash_value = self.generate_hash(inp_vec)\n",
        "        self.hash_table[hash_value] = self.hash_table\\\n",
        "            .get(hash_value, list()) + [label]\n",
        "        \n",
        "    def __getitem__(self, inp_vec):\n",
        "        hash_value = self.generate_hash(inp_vec)\n",
        "        return self.hash_table.get(hash_value, [])\n",
        "        \n",
        "hash_table = HashTable(hash_size=4, inp_dimensions=20)"
      ],
      "metadata": {
        "id": "aERlQMwQkAqt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creates 'num_tables' hash tables of size specified by 'hash_size'. the inp_dimension keeps the number of input features. Afterward, finds if two vectors are the same using at least one hashtable."
      ],
      "metadata": {
        "id": "kwKbYZJLSH6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSH:\n",
        "    def __init__(self, num_tables, hash_size, inp_dimensions):\n",
        "        self.num_tables = num_tables\n",
        "        self.hash_size = hash_size\n",
        "        self.inp_dimensions = inp_dimensions\n",
        "        self.hash_tables = list()\n",
        "        for i in range(self.num_tables):\n",
        "            self.hash_tables.append(HashTable(self.hash_size, self.inp_dimensions))\n",
        "    \n",
        "    def __setitem__(self, inp_vec, label):\n",
        "        for table in self.hash_tables:\n",
        "            table[inp_vec] = label\n",
        "    \n",
        "    def __getitem__(self, inp_vec):\n",
        "        results = list()\n",
        "        for table in self.hash_tables:\n",
        "            results.extend(table[inp_vec])\n",
        "        return list(set(results))\n",
        "    \n",
        "    def generate_projection(self, inp_vec):\n",
        "      projections = [ hash_table.generate_hash(inp_vec) for hash_table in self.hash_tables]\n",
        "      return projections\n",
        "\n",
        "    def check_similarity(self, point_projections, in_vec_projections):\n",
        "      for point_table_projection, point_vec_projection in zip(point_projections, in_vec_projections):\n",
        "        if point_table_projection == point_vec_projection:\n",
        "          return True\n",
        "      return False\n",
        "    \n",
        "    def query(self, points, query_point):\n",
        "      in_vec_projections = self.generate_projection(query_point)\n",
        "      results = []\n",
        "      for ind, point in enumerate(points):\n",
        "        point_projections = self.generate_projection(point)\n",
        "        if self.check_similarity(point_projections, in_vec_projections):\n",
        "          results.append(ind)\n",
        "      return results\n",
        "        "
      ],
      "metadata": {
        "id": "-UdivVSZk2fQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we generated 1000 random vectors with the dimensions of 300 and used 20 hash tables hashing each vector to another vector of length 30. "
      ],
      "metadata": {
        "id": "q8WN3JmwWHWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 1000\n",
        "d = 300\n",
        "f = 100\n",
        "b = 20\n",
        "r = 30\n",
        "lsh = LSH(b, r, d)\n",
        "points = create_fake_data(N, d)\n",
        "in_vec =  create_fake_data(1, d)\n",
        "results_lsh = lsh.query(points ,in_vec)\n",
        "results_k_farest = find_k_farest_neighbours(points, in_vec, 100)"
      ],
      "metadata": {
        "id": "ivvfJleMpGy9"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}